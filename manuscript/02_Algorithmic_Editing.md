# Chapter 2 — Algorithmic Editing of the Information Space

## 2.1 From human intention to computational selection
The transition from human-curated media to algorithmically optimized information flows marks a structural rupture in the architecture of the public sphere. Traditional media institutions operated through editorial judgment, ideological commitments, and professional norms. Their decisions—however biased—were grounded in **intentionality**.

Algorithmic systems, by contrast, do not select information based on intention but on **optimization**. The criterion is not truth, relevance, or public value, but the maximization of a predefined objective function: engagement, retention, virality, or predictive accuracy.

This shift replaces the logic of **decision** with the logic of **calculation**, extending the transformation described in Chapter 1. The information space becomes a computational environment in which visibility is determined by statistical fit rather than political or ethical judgment.

## 2.2 The rise of the quasi-will: optimization as a new form of agency
The algorithmic curation of information introduces a new form of agency that is neither human nor mechanical. The objective function acts as a **quasi-will**—a non-conscious, non-intentional, yet directive force that shapes collective perception.

This quasi-will is:
- **opaque**: its internal logic cannot be fully understood even by its creators  
- **non-teleological**: it pursues no narrative, mission, or moral horizon  
- **self-reinforcing**: optimization loops amplify their own outputs  
- **non-negotiable**: it cannot be persuaded, appealed to, or held accountable  

In premodern political theology, divine will was inscrutable but meaningful. In algorithmic governance, the quasi-will is inscrutable **and meaningless**.

## 2.3 Auto-generated atmospheres and the collapse of deliberation
Algorithmic editing does not merely filter information; it **constructs atmospheres**—affective climates that shape how events are interpreted before they are even understood.

These atmospheres emerge from:
- real-time emotional feedback  
- reinforcement of high-arousal content  
- clustering of users into affective micro-publics  
- amplification of conflictual narratives  

The result is a public sphere that is no longer discursive but **reactive**. Deliberation collapses because the informational environment is optimized for emotional activation rather than rational engagement.

## 2.4 The disappearance of authorship and the problem of accountability
In traditional propaganda systems, responsibility could be traced to identifiable actors: states, parties, media conglomerates. In algorithmic editing, responsibility dissolves.

Three forms of disappearance occur:
- **disappearance of the editor**: no human selects the content  
- **disappearance of the author**: content is generated, remixed, or amplified without clear origin  
- **disappearance of the decision**: outcomes emerge from optimization, not intention  

This produces a political environment in which no one can be blamed, no one can be held accountable, and no one can be removed from power—because power is not held by a person or institution but by **a process**.

## 2.5 Algorithmic visibility as the new criterion of chosenness
The information space becomes the primary site where **algorithmic chosenness** is enacted. Visibility is no longer a function of merit, authority, or legitimacy, but of **compatibility with the optimization logic**.

Those who are amplified are not “chosen” in any metaphysical or moral sense. They are simply **fit**—their features align with the model’s internal structure.

This produces a new hierarchy:
- **amplified subjects**  
- **neutral subjects**  
- **noisy subjects** (suppressed as statistical anomalies)  

The last category corresponds to **abandoned populations**—not persecuted, but ignored; not oppressed, but erased.

## 2.6 The information space as an automated exception machine
Algorithmic editing modulates the boundaries of the political field itself. When attention surges, the system amplifies it, often triggering moral panics, reputational collapses, mass outrage, or emergency measures. When attention collapses, issues disappear from public consciousness, enabling structural violence, corruption, surveillance, and abandonment.

Thus, the information space becomes an **exception machine**—a system that automatically generates zones of hyper-visibility and zones of invisibility.

## 2.7 Conclusion of Chapter 2
Algorithmic editing transforms the information space into a computational environment governed by a quasi-will. Deliberation collapses into affective atmospheres. Authorship and accountability disappear. Visibility becomes the criterion of algorithmic chosenness. And the boundaries of the political field are continuously redrawn by optimization processes.

In this environment, sovereignty is exercised not through decisions but through **the automated modulation of attention**.

